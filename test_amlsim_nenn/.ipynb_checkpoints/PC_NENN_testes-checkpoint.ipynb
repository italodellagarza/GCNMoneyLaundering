{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d772c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch_geometric.data import Data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "764b0bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "pt_files = []\n",
    "\n",
    "for ptfile in sorted(os.listdir('concept_drift_201')):\n",
    "    pt_files.append(f'concept_drift_201/{ptfile}')\n",
    "    dataset.append(torch.load(f'concept_drift_31/{ptfile}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32fe7f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    data = dataset[i]\n",
    "    edge_to_edge_adj_matr = torch.zeros(data.edge_to_edge_adj_matr.shape)\n",
    "    for n, ei in enumerate(data.edge_index.T):\n",
    "        for n2, ej in enumerate(data.edge_index.T):\n",
    "            if ei[1] == ej[1] or ei[1] == ej[0]:\n",
    "                edge_to_edge_adj_matr[n2, n] = 1.0\n",
    "    dataset[i].edge_to_edge_adj_matr = edge_to_edge_adj_matr.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3790d4f9",
   "metadata": {},
   "source": [
    "# Inicie aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb9d88be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch_geometric.data import Data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "75c2d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "pt_files = []\n",
    "\n",
    "for ptfile in sorted(os.listdir('concept_drift_201')):\n",
    "    pt_files.append(f'concept_drift_201/{ptfile}')\n",
    "    dataset.append(torch.load(f'concept_drift_201/{ptfile}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e39a2799",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = dataset[0].edge_to_edge_adj_matr.T.sum(1).diag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f936c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = dataset[0].edge_to_edge_adj_matr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f354d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Label frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f494c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f158670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf[1] = dataset[0].y.count_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4befcfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf[0] = len(dataset[0].y) - lf[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2b621f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: tensor(15), 0: tensor(67)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe23e8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "728e023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_frequencies = torch.tensor([lf[int(y)] for y in dataset[0].y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd91173f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([67, 67, 67, 67, 67, 67, 67, 67, 67, 15, 67, 67, 15, 15, 67, 67, 67, 67,\n",
       "        67, 67, 15, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67,\n",
       "        67, 15, 15, 67, 67, 67, 15, 67, 67, 67, 67, 67, 15, 67, 15, 67, 67, 15,\n",
       "        15, 67, 67, 67, 15, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67,\n",
       "        15, 67, 67, 67, 67, 15, 67, 15, 67, 67])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cb250b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_hat = torch.mul(D.pow(0.5), A)\n",
    "A_hat = torch.mul(A_hat, D.pow(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dea8e0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 2.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 2.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9fdd32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_e = A_hat[:,0].sum().pow(2)/label_frequencies[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ab9298f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0149)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a6de8037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "78107fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e09b7e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_probabilities(v):\n",
    "    return v/v.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b2f53f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(len(dataset)):\n",
    "    data = dataset[d]\n",
    "    D = data.edge_to_edge_adj_matr.T.sum(1).diag()\n",
    "    A = data.edge_to_edge_adj_matr.T\n",
    "    lf = dict()\n",
    "    lf[1] = data.y.count_nonzero()\n",
    "    lf[0] = len(data.y) - lf[1]\n",
    "    label_frequencies = torch.tensor([lf[int(y)] for y in data.y])\n",
    "    A_hat = torch.mul(D.pow(0.5), A)\n",
    "    A_hat = torch.mul(A_hat, D.pow(0.5))\n",
    "    probabilities = []\n",
    "    for i in range(len(data.edge_index.T)):\n",
    "        probabilities.append(A_hat[:,i].sum().pow(2).tolist()/label_frequencies[i].tolist())\n",
    "    probabilities = np.array(probabilities)\n",
    "    dataset[d].probabilities = torch.Tensor(to_probabilities(probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7f7c971e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0049, 0.0197, 0.0049, 0.0049, 0.0197, 0.0049, 0.0049, 0.0049, 0.0049,\n",
       "        0.0220, 0.0197, 0.0049, 0.0220, 0.0220, 0.0049, 0.0049, 0.0197, 0.0049,\n",
       "        0.0197, 0.0049, 0.0220, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049,\n",
       "        0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0197,\n",
       "        0.0049, 0.0881, 0.0220, 0.0049, 0.0049, 0.0049, 0.0220, 0.0049, 0.0049,\n",
       "        0.0197, 0.0049, 0.0049, 0.0220, 0.0197, 0.0220, 0.0197, 0.0197, 0.0220,\n",
       "        0.0881, 0.0049, 0.0197, 0.0049, 0.0220, 0.0049, 0.0049, 0.0049, 0.0049,\n",
       "        0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0197, 0.0049,\n",
       "        0.0220, 0.0049, 0.0049, 0.0197, 0.0049, 0.0220, 0.0049, 0.0220, 0.0197,\n",
       "        0.0049])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89e64e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398e1688",
   "metadata": {},
   "source": [
    "### Probabilidades geradas, agora implementar a etapa (PICK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91ac995a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e141c446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  7],\n",
       "        [ 0, 14],\n",
       "        [ 1, 30],\n",
       "        [ 1, 34],\n",
       "        [ 2,  6],\n",
       "        [ 2, 31],\n",
       "        [ 3, 31],\n",
       "        [ 3, 35],\n",
       "        [ 4, 12],\n",
       "        [ 4, 22],\n",
       "        [ 5,  3],\n",
       "        [ 5, 20],\n",
       "        [ 6,  9],\n",
       "        [ 6, 10],\n",
       "        [ 7, 17],\n",
       "        [ 7, 29],\n",
       "        [ 8, 15],\n",
       "        [ 8, 25],\n",
       "        [ 9, 11],\n",
       "        [ 9, 36],\n",
       "        [10, 18],\n",
       "        [10, 24],\n",
       "        [11,  0],\n",
       "        [11,  4],\n",
       "        [12,  5],\n",
       "        [12, 32],\n",
       "        [13,  8],\n",
       "        [13, 26],\n",
       "        [14,  2],\n",
       "        [14, 16],\n",
       "        [15, 23],\n",
       "        [15, 33],\n",
       "        [16, 21],\n",
       "        [16, 27],\n",
       "        [17, 19],\n",
       "        [17, 28],\n",
       "        [18,  1],\n",
       "        [18, 13]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].edge_to_node_adj_matr.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47982d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14,  7],\n",
       "        [34, 30],\n",
       "        [31,  6],\n",
       "        [31, 35],\n",
       "        [22, 12],\n",
       "        [20,  3],\n",
       "        [ 9, 10],\n",
       "        [17, 29],\n",
       "        [25, 15],\n",
       "        [36, 11],\n",
       "        [18, 24],\n",
       "        [ 0,  4],\n",
       "        [32,  5],\n",
       "        [ 8, 26],\n",
       "        [16,  2],\n",
       "        [33, 23],\n",
       "        [27, 21],\n",
       "        [19, 28],\n",
       "        [13,  1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].edge_index.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7de3894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# k = 2 vezes o tamanho da classe minoritária\n",
    "def pick(data, k):\n",
    "    if k > data.y.shape[0]:\n",
    "        return data\n",
    "    edges = np.random.choice(\n",
    "        a = np.array(range(data.edge_index.T.shape[0])),\n",
    "        p = data.probabilities.numpy(),\n",
    "        size = k,\n",
    "        replace=False\n",
    "    )\n",
    "    edges.sort()\n",
    "    #print(edges)\n",
    "    for edge, neighs in enumerate(data.edge_to_edge_adj_matr):\n",
    "        for neigh, is_neigh in enumerate(neighs):\n",
    "            if is_neigh == 1.0 and neigh != edge and not(neigh in edges):\n",
    "                edges = np.append(edges, neigh)\n",
    "    \n",
    "    new_edge_to_edge_adj_matr = data.edge_to_edge_adj_matr[edges][:,edges]\n",
    "    new_edge_to_node_adj_matr = data.edge_to_node_adj_matr[edges]\n",
    "    new_node_to_edge_adj_matr = data.node_to_edge_adj_matr[:,edges]\n",
    "    # Desfazer conexões e limpar vértices sem conexao zerados\n",
    "    nodes_used = new_edge_to_node_adj_matr.nonzero()[:,-1].unique()\n",
    "    new_node_to_node_adj_matr = torch.eye(data.node_to_node_adj_matr.shape[0])\n",
    "    for index in data.edge_index.T[edges]:\n",
    "        new_node_to_node_adj_matr[index[1]][index[0]] = 1.0\n",
    "        new_node_to_node_adj_matr[index[0]][index[1]] = 1.0\n",
    "    new_node_to_node_adj_matr = new_node_to_node_adj_matr[nodes_used][:,nodes_used]\n",
    "    new_node_to_node_adj_matr = new_node_to_node_adj_matr.T\n",
    "    new_edge_to_node_adj_matr = new_edge_to_node_adj_matr[:, nodes_used]\n",
    "    new_node_to_edge_adj_matr = new_node_to_edge_adj_matr[nodes_used]\n",
    "    \n",
    "    new_x = data.x.T[nodes_used].T\n",
    "    new_y = data.y.T[edges].T\n",
    "    new_edge_attr = data.edge_attr.T[edges].T\n",
    "    new_data = Data(\n",
    "        x = new_x,\n",
    "        y = new_y,\n",
    "        edge_attr = new_edge_attr,\n",
    "        edge_to_edge_adj_matr = new_edge_to_edge_adj_matr,\n",
    "        edge_to_node_adj_matr = new_edge_to_node_adj_matr,\n",
    "        node_to_edge_adj_matr = new_node_to_edge_adj_matr,\n",
    "        node_to_node_adj_matr = new_node_to_node_adj_matr\n",
    "    )\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "511240cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# k = 2 vezes o tamanho da classe minoritária\n",
    "def pick(data, k):\n",
    "    edges = np.random.choice(\n",
    "        a = np.array(range(data.edge_index.T.shape[0])),\n",
    "        p = data.probabilities.numpy(),\n",
    "        size = k,\n",
    "        replace=True\n",
    "    )\n",
    "    edges.sort()\n",
    "    #print(edges)\n",
    "    \n",
    "    new_edge_to_edge_adj_matr = data.edge_to_edge_adj_matr\n",
    "    new_edge_to_node_adj_matr = data.edge_to_node_adj_matr\n",
    "    new_node_to_edge_adj_matr = data.node_to_edge_adj_matr\n",
    "    new_edge_attr = data.edge_attr\n",
    "    new_y = data.y\n",
    "    #print(data.y)\n",
    "    for edge in edges:\n",
    "        new_edge_to_edge_adj_matr = torch.cat([new_edge_to_edge_adj_matr, new_edge_to_edge_adj_matr[edge].reshape([1,-1])])\n",
    "        new_edge_to_edge_adj_matr = torch.cat([new_edge_to_edge_adj_matr, new_edge_to_edge_adj_matr[:,edge].reshape([-1,1])], 1)\n",
    "        new_edge_to_edge_adj_matr[edge][edge] = 1.0\n",
    "        new_edge_to_node_adj_matr = torch.cat([new_edge_to_node_adj_matr, new_edge_to_node_adj_matr[edge].reshape([1,-1])])\n",
    "        new_node_to_edge_adj_matr = torch.cat([new_node_to_edge_adj_matr, new_node_to_edge_adj_matr[:,edge].reshape([-1,1])], 1)\n",
    "        new_edge_attr = torch.cat([new_edge_attr, new_edge_attr[:,edge].reshape([-1,1])], 1)\n",
    "        #print(new_y[edge])\n",
    "        new_y = torch.cat([new_y, new_y[edge].reshape([1])])\n",
    "    \n",
    "    new_x = data.x\n",
    "    new_data = Data(\n",
    "        x = new_x,\n",
    "        y = new_y,\n",
    "        edge_attr = new_edge_attr,\n",
    "        edge_to_edge_adj_matr = new_edge_to_edge_adj_matr,\n",
    "        edge_to_node_adj_matr = new_edge_to_node_adj_matr,\n",
    "        node_to_edge_adj_matr = new_node_to_edge_adj_matr,\n",
    "        node_to_node_adj_matr = data.node_to_node_adj_matr\n",
    "    )\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b4d68ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = torch.Tensor([[1,2,3], [4,5,6], [7,8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "238d6d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[0].reshape([1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d0939e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.],\n",
       "        [1., 2., 3.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([example, example[0].reshape([1,-1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0fa815d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 4., 7.])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "de760bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 1.],\n",
       "        [4., 5., 6., 4.],\n",
       "        [7., 8., 9., 7.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([example, example[:,0].reshape([-1,1])], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca9626df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[4].edge_to_node_adj_matr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4a7f9fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15) tensor(30)\n",
      "tensor(8) tensor(16)\n",
      "tensor(9) tensor(15)\n",
      "tensor(4) tensor(10)\n",
      "tensor(1) tensor(1)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(2) tensor(4)\n",
      "tensor(4) tensor(9)\n",
      "tensor(5) tensor(12)\n",
      "tensor(2) tensor(5)\n",
      "tensor(4) tensor(10)\n",
      "tensor(1) tensor(1)\n",
      "tensor(3) tensor(6)\n",
      "tensor(2) tensor(4)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(2) tensor(3)\n",
      "tensor(3) tensor(8)\n",
      "tensor(1) tensor(2)\n",
      "tensor(0) tensor(0)\n",
      "tensor(5) tensor(8)\n",
      "tensor(2) tensor(4)\n",
      "tensor(15) tensor(26)\n",
      "tensor(8) tensor(14)\n",
      "tensor(3) tensor(5)\n",
      "tensor(6) tensor(10)\n",
      "tensor(3) tensor(4)\n",
      "tensor(8) tensor(17)\n",
      "tensor(6) tensor(14)\n",
      "tensor(6) tensor(13)\n",
      "tensor(4) tensor(7)\n",
      "tensor(8) tensor(17)\n",
      "tensor(5) tensor(8)\n",
      "tensor(8) tensor(18)\n",
      "tensor(4) tensor(7)\n",
      "tensor(4) tensor(9)\n",
      "tensor(6) tensor(11)\n",
      "tensor(5) tensor(10)\n",
      "tensor(7) tensor(14)\n",
      "tensor(2) tensor(5)\n",
      "tensor(3) tensor(8)\n",
      "tensor(8) tensor(18)\n",
      "tensor(5) tensor(10)\n",
      "tensor(8) tensor(16)\n",
      "tensor(11) tensor(24)\n",
      "tensor(5) tensor(8)\n",
      "tensor(11) tensor(22)\n",
      "tensor(7) tensor(12)\n",
      "tensor(4) tensor(8)\n",
      "tensor(10) tensor(22)\n",
      "tensor(3) tensor(5)\n",
      "tensor(3) tensor(5)\n",
      "tensor(6) tensor(10)\n",
      "tensor(7) tensor(14)\n",
      "tensor(6) tensor(14)\n",
      "tensor(7) tensor(13)\n",
      "tensor(3) tensor(7)\n",
      "tensor(1) tensor(3)\n",
      "tensor(3) tensor(7)\n",
      "tensor(3) tensor(5)\n",
      "tensor(3) tensor(5)\n",
      "tensor(1) tensor(3)\n",
      "tensor(0) tensor(0)\n",
      "tensor(5) tensor(9)\n",
      "tensor(3) tensor(7)\n",
      "tensor(2) tensor(5)\n",
      "tensor(4) tensor(7)\n",
      "tensor(1) tensor(3)\n",
      "tensor(1) tensor(2)\n",
      "tensor(2) tensor(2)\n",
      "tensor(3) tensor(5)\n",
      "tensor(3) tensor(5)\n",
      "tensor(0) tensor(0)\n",
      "tensor(2) tensor(4)\n",
      "tensor(0) tensor(0)\n",
      "tensor(4) tensor(10)\n",
      "tensor(0) tensor(0)\n",
      "tensor(2) tensor(4)\n",
      "tensor(2) tensor(4)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(2)\n",
      "tensor(3) tensor(7)\n",
      "tensor(1) tensor(2)\n",
      "tensor(2) tensor(4)\n",
      "tensor(1) tensor(2)\n",
      "tensor(6) tensor(10)\n",
      "tensor(1) tensor(1)\n",
      "tensor(4) tensor(9)\n",
      "tensor(1) tensor(1)\n",
      "tensor(0) tensor(0)\n",
      "tensor(3) tensor(6)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(2) tensor(4)\n",
      "tensor(2) tensor(4)\n",
      "tensor(2) tensor(5)\n",
      "tensor(12) tensor(27)\n",
      "tensor(2) tensor(4)\n",
      "tensor(1) tensor(3)\n",
      "tensor(2) tensor(6)\n",
      "tensor(4) tensor(8)\n",
      "tensor(3) tensor(5)\n",
      "tensor(5) tensor(12)\n",
      "tensor(3) tensor(6)\n",
      "tensor(0) tensor(0)\n",
      "tensor(3) tensor(8)\n",
      "tensor(2) tensor(3)\n",
      "tensor(5) tensor(10)\n",
      "tensor(7) tensor(15)\n",
      "tensor(2) tensor(3)\n",
      "tensor(2) tensor(5)\n",
      "tensor(4) tensor(9)\n",
      "tensor(2) tensor(3)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(2)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(2) tensor(3)\n",
      "tensor(1) tensor(3)\n",
      "tensor(2) tensor(5)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(1)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(1)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(6) tensor(16)\n",
      "tensor(1) tensor(2)\n",
      "tensor(1) tensor(2)\n",
      "tensor(1) tensor(1)\n",
      "tensor(6) tensor(15)\n",
      "tensor(1) tensor(1)\n",
      "tensor(2) tensor(4)\n",
      "tensor(1) tensor(1)\n",
      "tensor(5) tensor(9)\n",
      "tensor(0) tensor(0)\n",
      "tensor(2) tensor(5)\n",
      "tensor(2) tensor(3)\n",
      "tensor(3) tensor(7)\n",
      "tensor(1) tensor(2)\n",
      "tensor(7) tensor(19)\n",
      "tensor(5) tensor(12)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(4) tensor(7)\n",
      "tensor(4) tensor(6)\n",
      "tensor(3) tensor(6)\n",
      "tensor(3) tensor(4)\n",
      "tensor(2) tensor(4)\n",
      "tensor(4) tensor(9)\n",
      "tensor(0) tensor(0)\n",
      "tensor(2) tensor(3)\n",
      "tensor(2) tensor(4)\n",
      "tensor(1) tensor(2)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(3)\n",
      "tensor(3) tensor(5)\n",
      "tensor(15) tensor(31)\n",
      "tensor(8) tensor(15)\n",
      "tensor(3) tensor(8)\n",
      "tensor(6) tensor(14)\n",
      "tensor(3) tensor(5)\n",
      "tensor(8) tensor(16)\n",
      "tensor(9) tensor(20)\n",
      "tensor(6) tensor(12)\n",
      "tensor(6) tensor(12)\n",
      "tensor(4) tensor(8)\n",
      "tensor(5) tensor(9)\n",
      "tensor(8) tensor(15)\n",
      "tensor(4) tensor(5)\n",
      "tensor(4) tensor(10)\n",
      "tensor(6) tensor(14)\n",
      "tensor(5) tensor(13)\n",
      "tensor(7) tensor(14)\n",
      "tensor(1) tensor(2)\n",
      "tensor(2) tensor(4)\n",
      "tensor(3) tensor(5)\n",
      "tensor(5) tensor(10)\n",
      "tensor(7) tensor(14)\n",
      "tensor(7) tensor(14)\n",
      "tensor(3) tensor(8)\n",
      "tensor(7) tensor(17)\n",
      "tensor(5) tensor(13)\n",
      "tensor(5) tensor(11)\n",
      "tensor(16) tensor(32)\n",
      "tensor(2) tensor(3)\n",
      "tensor(14) tensor(26)\n",
      "tensor(7) tensor(16)\n",
      "tensor(6) tensor(14)\n",
      "tensor(6) tensor(11)\n",
      "tensor(15) tensor(31)\n",
      "tensor(7) tensor(15)\n",
      "tensor(4) tensor(7)\n",
      "tensor(5) tensor(10)\n",
      "tensor(5) tensor(11)\n",
      "tensor(6) tensor(13)\n",
      "tensor(4) tensor(8)\n",
      "tensor(5) tensor(10)\n",
      "tensor(2) tensor(6)\n",
      "tensor(3) tensor(5)\n",
      "tensor(4) tensor(11)\n",
      "tensor(5) tensor(8)\n",
      "tensor(2) tensor(5)\n",
      "tensor(4) tensor(7)\n",
      "tensor(3) tensor(7)\n",
      "tensor(3) tensor(4)\n",
      "tensor(4) tensor(7)\n",
      "tensor(4) tensor(8)\n",
      "tensor(1) tensor(2)\n",
      "tensor(5) tensor(10)\n",
      "tensor(1) tensor(1)\n",
      "tensor(1) tensor(1)\n",
      "tensor(1) tensor(2)\n",
      "tensor(1) tensor(3)\n",
      "tensor(1) tensor(3)\n",
      "tensor(0) tensor(0)\n",
      "tensor(2) tensor(4)\n",
      "tensor(2) tensor(4)\n",
      "tensor(7) tensor(14)\n",
      "tensor(7) tensor(10)\n",
      "tensor(1) tensor(3)\n",
      "tensor(1) tensor(2)\n",
      "tensor(1) tensor(2)\n",
      "tensor(1) tensor(2)\n",
      "tensor(4) tensor(7)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(2) tensor(4)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(2)\n",
      "tensor(2) tensor(5)\n",
      "tensor(1) tensor(3)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(1)\n",
      "tensor(1) tensor(3)\n",
      "tensor(4) tensor(9)\n",
      "tensor(4) tensor(8)\n",
      "tensor(1) tensor(3)\n",
      "tensor(0) tensor(0)\n",
      "tensor(3) tensor(7)\n",
      "tensor(0) tensor(0)\n",
      "tensor(2) tensor(5)\n",
      "tensor(2) tensor(4)\n",
      "tensor(1) tensor(1)\n",
      "tensor(1) tensor(1)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(2)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(3) tensor(8)\n",
      "tensor(0) tensor(0)\n",
      "tensor(3) tensor(7)\n",
      "tensor(1) tensor(2)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(2)\n",
      "tensor(1) tensor(1)\n",
      "tensor(0) tensor(0)\n",
      "tensor(2) tensor(4)\n",
      "tensor(1) tensor(1)\n",
      "tensor(1) tensor(2)\n",
      "tensor(4) tensor(9)\n",
      "tensor(4) tensor(10)\n",
      "tensor(2) tensor(5)\n",
      "tensor(0) tensor(0)\n",
      "tensor(2) tensor(3)\n",
      "tensor(4) tensor(9)\n",
      "tensor(1) tensor(2)\n",
      "tensor(2) tensor(5)\n",
      "tensor(4) tensor(8)\n",
      "tensor(2) tensor(6)\n",
      "tensor(3) tensor(7)\n",
      "tensor(6) tensor(13)\n",
      "tensor(1) tensor(2)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(2) tensor(3)\n",
      "tensor(0) tensor(0)\n",
      "tensor(2) tensor(5)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(1)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(3)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(2)\n",
      "tensor(3) tensor(5)\n",
      "tensor(3) tensor(5)\n",
      "tensor(5) tensor(7)\n",
      "tensor(7) tensor(14)\n",
      "tensor(3) tensor(6)\n",
      "tensor(3) tensor(9)\n",
      "tensor(5) tensor(10)\n",
      "tensor(3) tensor(5)\n",
      "tensor(5) tensor(10)\n",
      "tensor(0) tensor(0)\n",
      "tensor(5) tensor(12)\n",
      "tensor(2) tensor(3)\n",
      "tensor(0) tensor(0)\n",
      "tensor(9) tensor(22)\n",
      "tensor(3) tensor(8)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(1)\n",
      "tensor(0) tensor(0)\n",
      "tensor(3) tensor(4)\n",
      "tensor(2) tensor(3)\n",
      "tensor(1) tensor(3)\n",
      "tensor(1) tensor(2)\n",
      "tensor(2) tensor(3)\n",
      "tensor(2) tensor(2)\n",
      "tensor(8) tensor(15)\n",
      "tensor(5) tensor(14)\n",
      "tensor(2) tensor(4)\n",
      "tensor(1) tensor(2)\n",
      "tensor(2) tensor(2)\n",
      "tensor(7) tensor(12)\n",
      "tensor(0) tensor(0)\n",
      "tensor(4) tensor(8)\n",
      "tensor(4) tensor(9)\n",
      "tensor(2) tensor(3)\n",
      "tensor(1) tensor(2)\n",
      "tensor(7) tensor(16)\n",
      "tensor(5) tensor(13)\n",
      "tensor(2) tensor(5)\n",
      "tensor(4) tensor(9)\n",
      "tensor(2) tensor(4)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(2)\n",
      "tensor(2) tensor(4)\n",
      "tensor(2) tensor(4)\n",
      "tensor(0) tensor(0)\n",
      "tensor(5) tensor(9)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(1)\n",
      "tensor(2) tensor(6)\n",
      "tensor(1) tensor(2)\n",
      "tensor(0) tensor(0)\n",
      "tensor(2) tensor(4)\n",
      "tensor(2) tensor(5)\n",
      "tensor(0) tensor(0)\n",
      "tensor(6) tensor(11)\n",
      "tensor(3) tensor(7)\n",
      "tensor(1) tensor(2)\n",
      "tensor(0) tensor(0)\n",
      "tensor(2) tensor(6)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(2)\n",
      "tensor(0) tensor(0)\n",
      "tensor(3) tensor(8)\n",
      "tensor(3) tensor(7)\n",
      "tensor(1) tensor(3)\n"
     ]
    }
   ],
   "source": [
    "nonzero_old = 0\n",
    "nonzero_new = 0\n",
    "total_old = 0\n",
    "total_new = 0\n",
    "\n",
    "for data in dataset:\n",
    "    new = pick(data, (data.y.count_nonzero()).tolist() * 2)\n",
    "    nonzero_old += data.y.count_nonzero()\n",
    "    nonzero_new += new.y.count_nonzero()\n",
    "    total_old += data.y.shape[0]\n",
    "    total_new += new.y.shape[0]\n",
    "    print(data.y.count_nonzero(), new.y.count_nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936637ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_old/total_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1459528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_new/total_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60afe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_picked = pick(dataset[4], (dataset[4].y.count_nonzero()).tolist() * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b84fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_picked.y.count_nonzero()/len(data_picked.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17b571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0].y.count_nonzero()/len(dataset[0].y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b1f503",
   "metadata": {},
   "source": [
    "# Arquitetura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2adb402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset[0:int(0.8*366)]\n",
    "test_data = dataset[int(0.8*366):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "dff4e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_nenn import Nenn\n",
    "model = Nenn(6,8,6,8,2)\n",
    "model = model.to('cpu')\n",
    "loss = torch.nn.CrossEntropyLoss(weight=torch.Tensor([0.2, 0.8]))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "325ec69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_original 17119\n",
      "train_new 35239\n",
      "epoch = 1 loss = 0.6525336503982544\n",
      "train_original 17119\n",
      "train_new 35239\n",
      "epoch = 2 loss = 0.5980292558670044\n",
      "train_original 17119\n",
      "train_new 35239\n",
      "epoch = 3 loss = 0.5371387004852295\n",
      "train_original 17119\n",
      "train_new 35239\n",
      "epoch = 4 loss = 0.476455420255661\n",
      "train_original 17119\n",
      "train_new 35239\n",
      "epoch = 5 loss = 0.42459312081336975\n",
      "train_original 17119\n",
      "train_new 35239\n",
      "epoch = 6 loss = 0.38365688920021057\n",
      "train_original 17119\n",
      "train_new 35239\n",
      "epoch = 7 loss = 0.3548387587070465\n",
      "train_original 17119\n",
      "train_new 35239\n",
      "epoch = 8 loss = 0.33707478642463684\n",
      "train_original 17119\n",
      "train_new 35239\n",
      "epoch = 9 loss = 0.3267477750778198\n",
      "train_original 17119\n",
      "train_new 35239\n",
      "epoch = 10 loss = 0.32098454236984253\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(10):\n",
    "    train_examples_original = 0\n",
    "    train_examples_new = 0\n",
    "    for ts, data in enumerate(train_data):\n",
    "        \n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Send info to the model\n",
    "        \n",
    "        data_picked = pick(data, (data.y.count_nonzero()).tolist() * 20)\n",
    "        train_examples_original += data.y.shape[0]\n",
    "        train_examples_new += data_picked.y.shape[0]\n",
    "        #data_picked = data\n",
    "        if data_picked.y.shape[0] == 0:\n",
    "            data_picked = data\n",
    "        \n",
    "        #data_picked = data\n",
    "        data_picked.to('cpu')\n",
    "        #print(data_picked.y.shape[0], data.y.shape[0])\n",
    "        logits, _ = model(\n",
    "            data_picked.x.T.type(torch.FloatTensor),\n",
    "            data_picked.edge_attr.T.type(torch.FloatTensor),\n",
    "            data_picked.edge_to_edge_adj_matr.T.type(torch.FloatTensor),\n",
    "            data_picked.edge_to_node_adj_matr.T.type(torch.FloatTensor),\n",
    "            data_picked.node_to_edge_adj_matr.T.type(torch.FloatTensor),\n",
    "            data_picked.node_to_node_adj_matr.T.type(torch.FloatTensor)\n",
    "        )\n",
    "        # Calculate loss\n",
    "        l = loss(logits, data_picked.y)\n",
    "        l.backward()\n",
    "        # Update gradients\n",
    "        optimizer.step()\n",
    "    print('train_original', train_examples_original)\n",
    "    print('train_new', train_examples_new)\n",
    "    print('epoch =', epoch + 1, 'loss =', l.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c42586df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/italo/Dissertacao_mestrado/GCNMoneyLaundering/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "label_pred_list = []\n",
    "y_true_list = []\n",
    "\n",
    "# Model evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_data:\n",
    "        data.to('cpu')\n",
    "        logits, _ = model(\n",
    "            data.x.T.type(torch.FloatTensor),\n",
    "            data.edge_attr.T.type(torch.FloatTensor),\n",
    "            data.edge_to_edge_adj_matr.T.type(torch.FloatTensor),\n",
    "            data.edge_to_node_adj_matr.T.type(torch.FloatTensor),\n",
    "            data.node_to_edge_adj_matr.T.type(torch.FloatTensor),\n",
    "            data.node_to_node_adj_matr.T.type(torch.FloatTensor)\n",
    "        )\n",
    "        label_pred = logits.max(1)[1].tolist()\n",
    "        label_pred_list += label_pred\n",
    "        y_true_list += data.y.tolist()\n",
    "prec_macro = precision_score(y_true_list, label_pred_list, average='macro')\n",
    "rec_macro = recall_score(y_true_list, label_pred_list, average='macro')\n",
    "f1_macro = f1_score(y_true_list, label_pred_list, average='macro')\n",
    "\n",
    "prec_0 = precision_score(y_true_list, label_pred_list, average='binary', labels=[0])\n",
    "rec_0 = recall_score(y_true_list, label_pred_list, average='binary', labels=[0])\n",
    "f1_0 = f1_score(y_true_list, label_pred_list, average='binary', labels=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "861a4e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      4136\n",
      "           1       0.04      1.00      0.07       165\n",
      "\n",
      "    accuracy                           0.04      4301\n",
      "   macro avg       0.02      0.50      0.04      4301\n",
      "weighted avg       0.00      0.04      0.00      4301\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/italo/Dissertacao_mestrado/GCNMoneyLaundering/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/italo/Dissertacao_mestrado/GCNMoneyLaundering/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/italo/Dissertacao_mestrado/GCNMoneyLaundering/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true_list,label_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053f0a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
