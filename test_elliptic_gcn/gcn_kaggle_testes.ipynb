{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c879cda",
   "metadata": {},
   "source": [
    "# Testes com a GCN implementada no Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9d7e39",
   "metadata": {},
   "source": [
    "Foi encontrada uma implementação da GCN utilizada no artigo [\"Anti-Money Laundering in Bitcoin: Experimenting with Graph Convolutional Networks for Financial Forensics\"][1], porém implementada em Pytorch puro. Essa implementação foi [encontrada no Kaggle][2]. Verficou-se que não há diferença significativa nos resultados das versões do Pytorch Geometric e essa versão.\n",
    "\n",
    "[1]: https://arxiv.org/pdf/1908.02591.pdf\n",
    "[2]: https://www.kaggle.com/karthikapv/gcn-elliptic-dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "474209ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57751e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for i in range(1,35):\n",
    "    train_data.append(torch.load('elliptic_pt/train/' + str(i) + '.pt'))\n",
    "\n",
    "for i in range(35,50):\n",
    "    test_data.append(torch.load('elliptic_pt/test/' + str(i) + '.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e079ccdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[2147, 166], edge_index=[2, 1924], y=[2147], adjacency_matrix=[2147, 2147]),\n",
       " Data(x=[1117, 166], edge_index=[2, 858], y=[1117], adjacency_matrix=[1117, 1117]),\n",
       " Data(x=[1279, 166], edge_index=[2, 727], y=[1279], adjacency_matrix=[1279, 1279]),\n",
       " Data(x=[1440, 166], edge_index=[2, 1169], y=[1440], adjacency_matrix=[1440, 1440]),\n",
       " Data(x=[1882, 166], edge_index=[2, 1491], y=[1882], adjacency_matrix=[1882, 1882]),\n",
       " Data(x=[485, 166], edge_index=[2, 209], y=[485], adjacency_matrix=[485, 485]),\n",
       " Data(x=[1203, 166], edge_index=[2, 858], y=[1203], adjacency_matrix=[1203, 1203]),\n",
       " Data(x=[1165, 166], edge_index=[2, 1044], y=[1165], adjacency_matrix=[1165, 1165]),\n",
       " Data(x=[778, 166], edge_index=[2, 484], y=[778], adjacency_matrix=[778, 778]),\n",
       " Data(x=[972, 166], edge_index=[2, 538], y=[972], adjacency_matrix=[972, 972]),\n",
       " Data(x=[696, 166], edge_index=[2, 477], y=[696], adjacency_matrix=[696, 696]),\n",
       " Data(x=[506, 166], edge_index=[2, 446], y=[506], adjacency_matrix=[506, 506]),\n",
       " Data(x=[809, 166], edge_index=[2, 564], y=[809], adjacency_matrix=[809, 809]),\n",
       " Data(x=[417, 166], edge_index=[2, 350], y=[417], adjacency_matrix=[417, 417]),\n",
       " Data(x=[618, 166], edge_index=[2, 446], y=[618], adjacency_matrix=[618, 618]),\n",
       " Data(x=[530, 166], edge_index=[2, 334], y=[530], adjacency_matrix=[530, 530]),\n",
       " Data(x=[811, 166], edge_index=[2, 673], y=[811], adjacency_matrix=[811, 811]),\n",
       " Data(x=[389, 166], edge_index=[2, 275], y=[389], adjacency_matrix=[389, 389]),\n",
       " Data(x=[745, 166], edge_index=[2, 585], y=[745], adjacency_matrix=[745, 745]),\n",
       " Data(x=[900, 166], edge_index=[2, 613], y=[900], adjacency_matrix=[900, 900]),\n",
       " Data(x=[641, 166], edge_index=[2, 518], y=[641], adjacency_matrix=[641, 641]),\n",
       " Data(x=[1763, 166], edge_index=[2, 1537], y=[1763], adjacency_matrix=[1763, 1763]),\n",
       " Data(x=[1187, 166], edge_index=[2, 1046], y=[1187], adjacency_matrix=[1187, 1187]),\n",
       " Data(x=[1126, 166], edge_index=[2, 961], y=[1126], adjacency_matrix=[1126, 1126]),\n",
       " Data(x=[594, 166], edge_index=[2, 559], y=[594], adjacency_matrix=[594, 594]),\n",
       " Data(x=[517, 166], edge_index=[2, 346], y=[517], adjacency_matrix=[517, 517]),\n",
       " Data(x=[206, 166], edge_index=[2, 58], y=[206], adjacency_matrix=[206, 206]),\n",
       " Data(x=[284, 166], edge_index=[2, 150], y=[284], adjacency_matrix=[284, 284]),\n",
       " Data(x=[1174, 166], edge_index=[2, 911], y=[1174], adjacency_matrix=[1174, 1174]),\n",
       " Data(x=[524, 166], edge_index=[2, 372], y=[524], adjacency_matrix=[524, 524]),\n",
       " Data(x=[710, 166], edge_index=[2, 522], y=[710], adjacency_matrix=[710, 710]),\n",
       " Data(x=[1323, 166], edge_index=[2, 997], y=[1323], adjacency_matrix=[1323, 1323]),\n",
       " Data(x=[441, 166], edge_index=[2, 429], y=[441], adjacency_matrix=[441, 441]),\n",
       " Data(x=[515, 166], edge_index=[2, 427], y=[515], adjacency_matrix=[515, 515])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3c91ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "\n",
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, in_features, out_features, activation  = 'relu', skip = False, skip_in_features = None):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.W = torch.nn.Parameter(torch.DoubleTensor(in_features, out_features))\n",
    "        nn.init.xavier_uniform_(self.W)\n",
    "        \n",
    "        self.set_act = False\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "            self.set_act = True\n",
    "        elif activation == 'softmax':\n",
    "            self.activation = nn.Softmax(dim = 1)\n",
    "            self.set_act = True\n",
    "        else:\n",
    "            self.set_act = False\n",
    "            raise ValueError(\"activations supported are 'relu' and 'softmax'\")\n",
    "            \n",
    "        self.skip = skip\n",
    "        if self.skip:\n",
    "            if skip_in_features == None:\n",
    "                raise ValueError(\"pass input feature size of the skip connection\")\n",
    "            self.W_skip = torch.nn.Parameter(torch.DoubleTensor(skip_in_features, out_features)) \n",
    "            nn.init.xavier_uniform_(self.W)\n",
    "        \n",
    "    def forward(self, A, H_in, H_skip_in = None):\n",
    "        # A must be an n x n matrix as it is an adjacency matrix\n",
    "        # H is the input of the node embeddings, shape will n x in_features\n",
    "        self.A = A\n",
    "        self.H_in = H_in\n",
    "        A_ = torch.add(self.A, torch.eye(self.A.shape[0]).double())\n",
    "        D_ = torch.diag(A_.sum(1))\n",
    "        # since D_ is a diagonal matrix, \n",
    "        # its root will be the roots of the diagonal elements on the principle diagonal\n",
    "        # since A is an adjacency matrix, we are only dealing with positive values \n",
    "        # all roots will be real\n",
    "        D_root_inv = torch.inverse(torch.sqrt(D_))\n",
    "        A_norm = torch.mm(torch.mm(D_root_inv, A_), D_root_inv)\n",
    "        # shape of A_norm will be n x n\n",
    "        \n",
    "        H_out = torch.mm(torch.mm(A_norm, H_in), self.W)\n",
    "        # shape of H_out will be n x out_features\n",
    "        \n",
    "        if self.skip:\n",
    "            H_skip_out = torch.mm(H_skip_in, self.W_skip)\n",
    "            H_out = torch.add(H_out, H_skip_out)\n",
    "        \n",
    "        if self.set_act:\n",
    "            H_out = self.activation(H_out)\n",
    "            \n",
    "        return H_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ce15009",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_2layer(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, skip = False):\n",
    "        super(GCN_2layer, self).__init__()\n",
    "        self.skip = skip\n",
    "        \n",
    "        self.gcl1 = GraphConv(in_features, hidden_features)\n",
    "        \n",
    "        if self.skip:\n",
    "            self.gcl_skip = GraphConv(hidden_features, out_features, activation = 'softmax', skip = self.skip,\n",
    "                                  skip_in_features = in_features)\n",
    "        else:\n",
    "            self.gcl2 = GraphConv(hidden_features, out_features, activation = 'softmax')\n",
    "        \n",
    "    def forward(self, A, X):\n",
    "        out = self.gcl1(A, X)\n",
    "        if self.skip:\n",
    "            out = self.gcl_skip(A, out, X)\n",
    "        else:\n",
    "            out = self.gcl2(A, out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc6a855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 999/1000 Timestamp 34 training loss: 0.319192 training accuracy: 0.996117 Time: 0.082777023315429698"
     ]
    }
   ],
   "source": [
    "num_features = 166\n",
    "num_classes = 2\n",
    "epochs = 1000\n",
    "lr = 0.001\n",
    "\n",
    "\n",
    "# 0 - illicit, 1 - licit\n",
    "#labels_ts = []\n",
    "#for c in classes_ts:\n",
    "#    labels_ts.append(np.array(c['class'] == '2', dtype = np.long))\n",
    "\n",
    "gcn = GCN_2layer(num_features, 100, num_classes)\n",
    "train_loss = nn.CrossEntropyLoss(weight = torch.DoubleTensor([0.7, 0.3]))\n",
    "optimizer = torch.optim.Adam(gcn.parameters(), lr = lr)\n",
    "\n",
    "# Training\n",
    "\n",
    "\n",
    "    \n",
    "for ep in range(epochs):\n",
    "    for ts, data in enumerate(train_data):\n",
    "        A = data.adjacency_matrix\n",
    "        X = data.x\n",
    "        L = data.y\n",
    "        t_start = time.time()\n",
    "        \n",
    "        gcn.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = gcn(A, X)\n",
    "\n",
    "        loss = train_loss(out, L)\n",
    "        train_pred = out.max(1)[1].type_as(L)\n",
    "        acc = (train_pred.eq(L).double().sum())/L.shape[0]\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sys.stdout.write(\"\\r Epoch %d/%d Timestamp %d training loss: %f training accuracy: %f Time: %s\"\n",
    "                         %(ep, epochs, ts+1, loss, acc, time.time() - t_start)\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c302830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "torch.save(gcn.state_dict(), str(os.path.join(\"./modelDir\", \"gcn_weights.pth\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de06be13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.50      0.60      1083\n",
      "           1       0.97      0.99      0.98     15587\n",
      "\n",
      "    accuracy                           0.96     16670\n",
      "   macro avg       0.86      0.74      0.79     16670\n",
      "weighted avg       0.95      0.96      0.95     16670\n",
      "\n",
      "GCN - averaged accuracy: 0.9492094623532064, precision: 0.9589358137173803, recall: 0.9875010187796687, f1: 0.9727337866538667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "\n",
    "gcn = GCN_2layer(num_features, 100, num_classes)\n",
    "gcn.load_state_dict(torch.load(os.path.join(\"./modelDir\", \"gcn_weights.pth\")))\n",
    "\n",
    "# Testing\n",
    "test_accs = []\n",
    "test_precisions = []\n",
    "test_recalls = []\n",
    "test_f1s = []\n",
    "total_L = []\n",
    "total_test_pred = []\n",
    "\n",
    "\n",
    "for data in test_data:\n",
    "    A = data.adjacency_matrix\n",
    "    X = data.x\n",
    "    L = data.y\n",
    "    \n",
    "    gcn.eval()\n",
    "    test_out = gcn(A, X)\n",
    "    \n",
    "    test_pred = test_out.max(1)[1].type_as(L)\n",
    "    t_acc = (test_pred.eq(L).double().sum())/L.shape[0]\n",
    "    test_accs.append(t_acc.item())\n",
    "    test_precisions.append(precision_score(L, test_pred))\n",
    "    test_recalls.append(recall_score(L, test_pred))\n",
    "    test_f1s.append(f1_score(L, test_pred))\n",
    "    total_L += L\n",
    "    total_test_pred += test_pred\n",
    "\n",
    "print(classification_report(total_L, total_test_pred))\n",
    "\n",
    "acc = np.array(test_accs).mean()\n",
    "prec = np.array(test_precisions).mean()\n",
    "rec = np.array(test_recalls).mean()\n",
    "f1 = np.array(test_f1s).mean()\n",
    "\n",
    "print(\"GCN - averaged accuracy: {}, precision: {}, recall: {}, f1: {}\".format(acc, prec, rec, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f190e2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[1341, 166], edge_index=[2, 1002], y=[1341], adjacency_matrix=[1341, 1341]),\n",
       " Data(x=[1708, 166], edge_index=[2, 1148], y=[1708], adjacency_matrix=[1708, 1708]),\n",
       " Data(x=[498, 166], edge_index=[2, 423], y=[498], adjacency_matrix=[498, 498]),\n",
       " Data(x=[756, 166], edge_index=[2, 653], y=[756], adjacency_matrix=[756, 756]),\n",
       " Data(x=[1183, 166], edge_index=[2, 1055], y=[1183], adjacency_matrix=[1183, 1183]),\n",
       " Data(x=[1211, 166], edge_index=[2, 1180], y=[1211], adjacency_matrix=[1211, 1211]),\n",
       " Data(x=[1132, 166], edge_index=[2, 1048], y=[1132], adjacency_matrix=[1132, 1132]),\n",
       " Data(x=[2154, 166], edge_index=[2, 1443], y=[2154], adjacency_matrix=[2154, 2154]),\n",
       " Data(x=[1370, 166], edge_index=[2, 935], y=[1370], adjacency_matrix=[1370, 1370]),\n",
       " Data(x=[1591, 166], edge_index=[2, 1497], y=[1591], adjacency_matrix=[1591, 1591]),\n",
       " Data(x=[1221, 166], edge_index=[2, 1346], y=[1221], adjacency_matrix=[1221, 1221]),\n",
       " Data(x=[712, 166], edge_index=[2, 388], y=[712], adjacency_matrix=[712, 712]),\n",
       " Data(x=[846, 166], edge_index=[2, 822], y=[846], adjacency_matrix=[846, 846]),\n",
       " Data(x=[471, 166], edge_index=[2, 371], y=[471], adjacency_matrix=[471, 471]),\n",
       " Data(x=[476, 166], edge_index=[2, 415], y=[476], adjacency_matrix=[476, 476])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
